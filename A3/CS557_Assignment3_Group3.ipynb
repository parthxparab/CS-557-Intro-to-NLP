{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS557_Assignment3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GHyONNXtfZ4"
      },
      "source": [
        "# **CS 557 - Assignment 3 (Detecting Spelling Errors, Minimum Edit Distance, Human Morphology and Sentiment Analysis with Naïve Bayesian Classification)**\n",
        "\n",
        "#### **Group 3 Members:**\n",
        "#### Parth Parab - CWID 10444835\n",
        "\n",
        "#### Sejal Vyas - CWID 10450395\n",
        "\n",
        "#### Shiwani Deo - CWID 10454959"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myznGBw4JJn5"
      },
      "source": [
        "# **1. Respond to J&M 2nd Exercises 3.10 and 3.11**\n",
        "\n",
        "### **3.10) Add an option to your program to generate random sentences.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsokoKSzbjZ1",
        "outputId": "990d410f-fec9-42e1-e6a8-28485012757e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import nltk, random, re, string, collections\n",
        "nltk.download('abc') #Using abc corpus for N-gram computation\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.util import bigrams,trigrams\n",
        "from nltk.corpus import abc, stopwords\n",
        "from collections import Counter, defaultdict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]   Package abc is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SvXZCLJoiYM",
        "outputId": "c070e0cf-9e37-4d8f-f09a-cd83c527679c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "#We will be using trigrams to generate random sentences\n",
        "def computeProbabilities():\n",
        "  model = defaultdict(lambda: defaultdict(lambda: 0)) #Nested dictionary\n",
        "\n",
        "  for sentence in abc.sents():\n",
        "      for word1, word2, word3 in trigrams(sentence, pad_right=True, pad_left=True): #Create Trigrams\n",
        "          model[(word1, word2)][word3] += 1\n",
        "\n",
        "  for wordTuple in model: #Compute probabilities of the trigrams\n",
        "      wordCount = float(sum(model[wordTuple].values()))\n",
        "      for word in model[wordTuple]:\n",
        "          model[wordTuple][word] /= wordCount\n",
        "  return model\n",
        "\n",
        "def generateSentence(noOfSentences=5):\n",
        "  model = computeProbabilities()\n",
        "  sentences = []\n",
        "  sentenceCount = 0\n",
        "  sentenceFinished = False\n",
        "  sentences = []\n",
        "  for i in range(0, noOfSentences):\n",
        "    paragraph=[None, None]\n",
        "    sentenceFinished = False\n",
        "    while not sentenceFinished:\n",
        "      randomProbability = random.uniform(0.6, 1.0) #Generate random probabilities between 0.6 and 1.0\n",
        "      probability = 0\n",
        "\n",
        "      for word in model[tuple(paragraph[-2:])].keys(): #Create trigram using the last 2 words from the generated text and a word in the model\n",
        "          probability += model[tuple(paragraph[-2:])][word]\n",
        "          if probability >= randomProbability: \n",
        "              paragraph.append(word)\n",
        "              break\n",
        "\n",
        "      if paragraph[-2:] == [None, None]: #If next words are 'None', sentence has ended. Append current line to sentences[] \n",
        "          sentenceFinished = True\n",
        "          sentences.append(paragraph)\n",
        "\n",
        "  finalParagraph = \"\"\n",
        "  for i in range (0, len(sentences)):\n",
        "    finalParagraph = finalParagraph + ' '.join([word for word in sentences[i] if word]) #Ignore words that are 'None' and create sentences from array of words\n",
        "\n",
        "  return finalParagraph                                  \n",
        "  \n",
        "generateSentence(10) #Parameter is an integer representing the number of sentences you want to generate. Default number = 5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Dean and her research is starting in north - south geographical distribution .Experts note the very reliable Argon - 39 years of thinking Farmers who want whaling banned Pro - whaling campaign .Dr Sandip Datta and colleagues publish their report ,\" he says , by day and age .Lamb feedlot shed open for boneless beef ,\" he says models also support the IAU meeting , and depressioNet .Horticulturalist Steven Falivene says growers want to understand , while he welcomes increased spending on it indicating that the Red Gulch ], but it can \\' t enough evidence to suggest an ethnic majority .SoL \\' s raining methane on Saturn \\' s pictures .Water would also repair an infrared spectrometer that has had several calls from the Viking instruments measured in the mirror and watched as it hits the photo - detecting fibres .Irrigators discuss compensation with Premier Morris Iemma to ask in public than younger adults about the luck of the voodoo cult who sometimes kill animals with a neighbour over a million years old , they spiral towards each other with each mirror 8 . 2 billion people get it in porous rocks deep below the past century .Such networks can consist of the ice could eventually drive more interest in livestock .Truck crash prompts stock movements warning Police in the British Pharmaceutical Industry and the chemistry behind this remains a throw back to chapter 13 and elsewhere may have damage to apples , apricots and cherries .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIK3uRWoUQts"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNxDAnogQq5B"
      },
      "source": [
        "### **3.11) Add an option to your program to compute the perplexity of a test set.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aM0VmFqaa-zq",
        "outputId": "cf806268-b297-4e0b-e127-aec152100b7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Perplexity using Unigrams\n",
        "#Corpus used: 'abc'\n",
        "\n",
        "def computeUnigramProbabilities():\n",
        "  model = collections.defaultdict(lambda: 0.01)\n",
        "\n",
        "  for word in abc.words(): #Compute probabilities of the Unigram\n",
        "    model[word] += 1\n",
        "  \n",
        "  wordCount = float(sum(model.values()))\n",
        "\n",
        "  for word in model: #Compute probabilities of the unigrams\n",
        "    model[word] /= wordCount\n",
        "  return model\n",
        "\n",
        "def unigramPerplexity(testData): #testData is a string (sentences)\n",
        "  model = computeUnigramProbabilities();\n",
        "  \n",
        "  testData = testData.split(' ')\n",
        "  perplexity = 1\n",
        "\n",
        "  for word in testData:\n",
        "    perplexity = perplexity*(1/model[word]) #Calculate P(w1 w2....wn)\n",
        "  perplexity = pow(perplexity, 1/len(testData))\n",
        "  return perplexity\n",
        "\n",
        "\n",
        "print(\"The perplexity of the test set is:\",unigramPerplexity(\"This is a test sentence for the abc corpus.\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The perplexity of the test set is: 404.85380039594196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGCmX_1EqUzR"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnmEQ44AqWEI"
      },
      "source": [
        "### **Q2. Find Python packages that apply Bayesian logic to classification and apply one to sentiment data**\n",
        "\n",
        "The following packages exist for Naïve Bayes classifier in python:\n",
        "- NLTK classifier, scikit-learn classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Pqghk3sNZgU",
        "outputId": "619dbabd-4259-4350-947a-c2ac7fd11cda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#Dataset used: https://www.cs.jhu.edu/~mdredze/datasets/sentiment/\n",
        "#Type of Data: Unprocessed data\n",
        "\n",
        "#Instructions: Upload attached two XML files 'positive.review' and 'negative.review' for the training data\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import string\n",
        "\n",
        "negRev = []\n",
        "posRev = []\n",
        "stopWords = set(stopwords.words('english')) \n",
        "\n",
        "#Get contents of negative review file\n",
        "f = open(\"/content/negative.review\", \"r\", encoding=\"ISO-8859-1\")\n",
        "soup = BeautifulSoup(f)\n",
        "for review in soup.find_all('review_text'):\n",
        "  negRev.append(review.text)\n",
        "\n",
        "#Get contents of positive review file\n",
        "f = open(\"/content/positive.review\", \"r\", encoding=\"ISO-8859-1\")\n",
        "soup = BeautifulSoup(f)\n",
        "for review in soup.find_all('review_text'):\n",
        "  posRev.append(review.text)  \n",
        "\n",
        "def isStopWord(word): #Check if input word is a stop word\n",
        "  return word in stopWords\n",
        "\n",
        "def processReviews(reviews, label):\n",
        "  documents = []\n",
        "  allWords = []\n",
        "  reviewWords = []\n",
        "  for line in reviews:\n",
        "    wordList = line.split(\" \") #Tokenize\n",
        "    for word in wordList:\n",
        "      word = word.strip('\\n') #Remove trailing new line character\n",
        "      word = re.sub(r'[^\\w\\s]','',word) #Remove punctuation\n",
        "      if(not isStopWord(word)): #Filter out stop words\n",
        "        reviewWords.append(word)\n",
        "        allWords.append(word)\n",
        "    \n",
        "    documents.append((reviewWords, label))\n",
        "  return documents, allWords\n",
        "\n",
        "def trainData():\n",
        "  negDocuments,allWords = processReviews(negRev, \"neg\")\n",
        "  posDocuments,posWords = processReviews(posRev, \"pos\")\n",
        "  negDocuments.extend(posDocuments) #Combine both negative and positive reviews\n",
        "  allWords.extend(posWords)\n",
        "  reviews = negDocuments \n",
        "  random.shuffle(reviews) #Shuffle all the reviews\n",
        "\n",
        "  freqWord = nltk.FreqDist(word.lower() for word in allWords)\n",
        "  wordFeatures = list(freqWord.keys())[:2000]\n",
        "\n",
        "  def documentFeatures(document):\n",
        "    documentWords = set(document) #Searching in a set is faster so convert to set\n",
        "    features = {}\n",
        "    for word in wordFeatures:\n",
        "      features['contains({})'.format(word)] = (word in documentWords) #Create bag of words \n",
        "    return features\n",
        "\n",
        "  featureSets = [(documentFeatures(review), label) for (review, label) in reviews] #Create feature set using bag of words\n",
        "  trainSetLength = int(len(featureSets)*0.75)\n",
        "  testSetLength =  int(len(featureSets)*0.25)\n",
        "  trainSet, testSet = featureSets[trainSetLength:], featureSets[:testSetLength]\n",
        "  classifier = nltk.NaiveBayesClassifier.train(trainSet) #Train Classifier\n",
        "\n",
        "  classifier.show_most_informative_features(5) #Display top 5 most informative features as interpreted by the classifier\n",
        "\n",
        "  print(\"\\nAccuracy is: \",nltk.classify.accuracy(classifier, testSet)) #Accuracy is 100% since it's trained on the same vocab\n",
        "\n",
        "trainData()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most Informative Features\n",
            "         contains(stars) = True              neg : pos    =      1.0 : 1.0\n",
            "    contains(advertised) = True              neg : pos    =      1.0 : 1.0\n",
            "          contains(does) = False             neg : pos    =      1.0 : 1.0\n",
            "         contains(price) = True              neg : pos    =      1.0 : 1.0\n",
            "\n",
            "Accuracy is:  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6knQGzqqi5md"
      },
      "source": [
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdUfrAyvjT5B"
      },
      "source": [
        "### **Q3. Briefly report on SentiWordNet and how it can be used with Python and WordNet to classify a corpus of reviews**\n",
        "\n",
        "\n",
        "#### **Introduction**\n",
        "SentiWordNet 3.0 is a resource for sentiment classification that utilizes synsets of Wordnet and assigns a numerical score of either positivity, negativity, or objective (neutrality). \n",
        "\n",
        "```\n",
        "e.g: The synset [estimable] has an objective score of 1.0, positive = 0.0, and negative = 0.0\n",
        "```\n",
        "One of the major differences between SentiWordNet version 1.0 and version 3.0 is that the semi-supervised learning algorithm used in version 1.0, for annotation, is just one of the steps in version 3.0, thus, making it more accurate.\n",
        "\n",
        "Steps involved in annotation generation process for SentiWordNet 3.0:\n",
        "\n",
        "**a) Step 1: Semi-Supervised Learning Step**\n",
        "- **Seed set expansion:** There are two sets, each having all the synsets containing 7 positive and 7 negative terms respectively. These sets are then expanded with a certain radius 'k'. This implies that synsets that are within distance 'k' from the original seed sets members are added to the same.\n",
        "- **Classifier Training:** The expanded seed sets in the previous set are used as the training set. If the classifier needs to predict an 'Object' label, another set of synsets with the *Obj* property is also included in the training. The only difference is, glosses of synsets are used for training instead of the synsets themselves.\n",
        "- **Synset Classification:** This step is straightforward, all the WordNet synsets are classified as either *Pos*, *Neg*, or *Obj* by using the trained classifier in step 2.\n",
        "- **Classifier Combination:** As mentioned in step 1, we create the synsets using the 'k' parameter. We can train the classifier in step 2 with different synsets depeneding upon the value of 'k'. Hence, in this step, we create a committee of ternary classifiers, each having a different combination of 'k' and learning algorithms.\n",
        "\n",
        "**b) Step 2: Random-walk Step**\n",
        "- This consists of a graph that runs iteratively using a random-walk. In the graph, a direct link exists only if synset s1 occurs in the gloss of synset s2. Two random-walk processes are executed, one for positive synsets, and one for negative synsets. First the pos and neg scores are fitted using the function $F_{Pos}(x) = a*x^b$ and similarly $F_{Neg}(x) = c*x^d$.\n",
        "Then the final values are determined with a resulting function. Once they are computed, the *Obj(s)* values are assigned such that the sum is 1. \n",
        "\n",
        "**Note:** If *Pos(s) + Neg(s) > 1*, the values are normalized.\n",
        "\n",
        "Testing has been done on both SentiWordNet 3.0 and SentiWordNet 1.0 to evaluate how it ranks positivity/negativity of the synsets in Micro-WN(Op)-3.0. Results state that SentiWordNet 3.0 is substantially more accurate than SentiWordNet 1.0 with an approximate 20% improvement in ranking positivity, and a 22% improvement in ranking negativity.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Usage of SentiWordNet with Python and WordNet:**\n",
        "\n",
        "Reference - [Reviews Classification Using SentiWordNet Lexicon](https://www.researchgate.net/publication/267249616_Reviews_Classification_Using_SentiWordNet_Lexicon\n",
        ")\n",
        "\n",
        "As dicussed above, SentiWordNet is a lexicon that assigns to each synset of WordNet three numerical scores - positivity, negativity, and objectivity (neutrality). Such lexicons that assign sentiment polarity are known as opinion lexicons. This can be used to classify a corpus of reviews efficiently. An important approach in detecting sentiment is to use a dictionary of opinionated terms.\n",
        "\n",
        "WordNet keeps track of the senses of a word. For example, there are 4 senses of the noun 'good', 21 senses of the adjective 'good', and 2 senses of the adverb 'good' in WordNet. The word sentiment interpretation is done by computing the number of times the 'word#sense' entry is positive as compared to negative along with the total number of entries. This helps determine the sentiment polarity. \n",
        "\n",
        "The following is a SentiWordNet Fragment:\n",
        "```\n",
        "Category | WNT Number |  pos  |  neg  | Synonyms\n",
        "-------- | ---------- | ----- | ----- | --------\n",
        "    A    | 01123148   | 0.875 | 0     | good#1\n",
        "    A    | 00106020   | 0     | 0     | good#2 full #6\n",
        "    A    | 01125429   | 0     | 0.625 | bad#1\n",
        "    A    | 01510444   | 0.25  | 0.25  | big#3 bad #2\n",
        "```\n",
        "**Technique to use SentiWordNet in Review Classification:**\n",
        "\n",
        "- **SentiWordNet Interpretation Phase:** As demonstrated by the table above, each word has multiple senses, this makes identifying positivity/negativity of a corpus difficult. Hence the first step is to perform word sense disambiguation(WSD). \n",
        "- **Sentiment Polarity Phase:** We need to take into account the magnitude of the positive and negative scores assigned by SentiWordNet.\n",
        "\n",
        "**Implementation:**\n",
        "\n",
        "- Dataset used: [Amazon Product Review Set](https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html)\n",
        "\n",
        "Before we use SentiWordNet for classification, we need to perform the following:\n",
        "- Tokenization - Split the text into tokens for processing\n",
        "- Sentence Splitting - Segment the text into sentences for the tagger\n",
        "- Speech tagging - Produce a part-of-speech tag on each word or symbol\n",
        "\n",
        "Once the above steps are completed, we can proceed with the classifier.\n",
        "\n",
        "There are 3 methods we can use:\n",
        "1. **Term Counting** - Sentiment polarity is determined by calculating the positive and negative scores. Then, the sentiment is assigned by categorizing the review based on the highest score. \n",
        "2. **Sum on Review** - The magnitude of scores is taken into account in this method, thus, the summation of the positive and negative scores for each term in the review is calculated and the sentiment is assigned accordingly.\n",
        "3. **Average on Sentence and Average on Review** - The average of positive and negative scores for each term in a sentence in a review is computed. Then, the average of the positive and negative scores of a sentence is computed. The sentiment is assigned based on which score has the highest value.\n",
        "\n",
        "The results of executing the above 3 methods on the corpus is as follows:\n",
        "```\n",
        "                Method                    | Accuracy (%)\n",
        "----------------------------------------- | ---------- | \n",
        "Term Counting                             | 56.77\n",
        "Sums on Review                            | 67.00\n",
        "Average on Sentence and Average on Review | 68.63\n",
        "```\n",
        "\n",
        "`from nltk.corpus import wordnet`\n",
        "\n",
        "`from nltk.corpus import sentiwordnet `\n",
        "\n",
        "The above modules in Python are available to carry out sentiment classification using SentiWordNet and WordNet.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZQgvncCc322"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoOO-cfXc4fH"
      },
      "source": [
        "### **Q4. (Exercise 4.3 from BKL) Train two models, multinominal naive Bayes and binarized naive Bayes, both with add-1 smoothing, on the following document counts for key sentiment words, with positive or negative class assigned as noted.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA5-ka5zdK5w",
        "outputId": "ccd53aec-ca43-4a6d-ec33-395b12843144",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "#Reference - https://kenzotakahashi.github.io/naive-bayes-from-scratch-in-python.html\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "sentence = \"A good, good plot and great characters, but poor acting.\" #Test sentence\n",
        "document = pd.DataFrame([[3,0,3, 'positive'], [0,1,2, 'positive'],[1,3,0, 'negative'],[1,5,2, 'negative'],[0,2,0, 'negative']], columns = ['good', 'poor', 'great', 'class'])\n",
        "classID = {'positive': 1, 'negative': 0}\n",
        "document['ID'] = document['class'].map(classID)\n",
        "\n",
        "class mainNaiveBayes(object):\n",
        "  def __init__(self, alpha=1.0): #Add-1 smoothing\n",
        "    self.alpha = alpha\n",
        "\n",
        "  def fitModel(self, x, y):\n",
        "    sampleCount = x.shape[0] #Get number of samples\n",
        "    separated = [[freq for freq, token in zip(x, y) if token == sClass] for sClass in np.unique(y)] #Grouping by class\n",
        "    self.computeLog = [np.log(len(freq)/sampleCount) for freq in separated] #Calculate log probability of each word (Count/length)\n",
        "    count = np.array([np.array(i).sum(axis=0) for i in separated]) + self.alpha\n",
        "    self.featureProb = np.log(count/count.sum(axis=1)[np.newaxis].T)\n",
        "    return self\n",
        "  \n",
        "  def predictLog(self, X):\n",
        "    return [(self.featureProb * freq).sum(axis=1) + self.computeLog for freq in X] #Predict log probability of each class\n",
        "  \n",
        "  def predict(self, X):\n",
        "    return np.argmax(self.predictLog(X), axis=1) #Pick maximum value of log probability\n",
        "\n",
        "def countFeatures(sentence):\n",
        "  goodCount = sentence.count(\"good\") \n",
        "  poorCount = sentence.count(\"poor\") \n",
        "  greatCount = sentence.count(\"great\") \n",
        "  sentenceCount = np.array([[goodCount, poorCount, greatCount]])\n",
        "  return sentenceCount\n",
        "\n",
        "def getPrediction(prediction):\n",
        "  if prediction==1:\n",
        "    return \"Positive\"\n",
        "  else:\n",
        "    return \"Negative\"\n",
        "\n",
        "def multinomialNaiveBayes():\n",
        "  print(\"\\nDataset for Multinomial Naive Bayes: \\n\",document)\n",
        "  wordCount = document.iloc[:, :-2].values #Extract the frequences from the document\n",
        "  labels = document.iloc[:, -1].values #Extract the classes(labels)\n",
        "  classifier = mainNaiveBayes().fitModel(wordCount, labels) #Fit the model\n",
        "  testSet = countFeatures(sentence) #Create feature set from the test sentence\n",
        "  print(\"\\nThe feature test set is: \", testSet)\n",
        "  predictedSentiment = classifier.predict(testSet)\n",
        "  print(\"Test Sentence: \", sentence)\n",
        "  print(\"Sentiment using Multinomial Naïve Bayes - \", getPrediction(predictedSentiment))\n",
        "\n",
        "\n",
        "def binarizedNaiveBayes():\n",
        "  for row in range(document.shape[0]):\n",
        "    for col in range(document.shape[1] - 2):\n",
        "      if(document.iloc[row, col] > 0): \n",
        "        document.iloc[row, col] = 1 #Since frequency does not matter in binarized Naive Bayes, set values to either 0 or 1\n",
        "  print(\"\\nDataset for Binarized Naive Bayes: \\n\",document)\n",
        "  wordCount = document.iloc[:, :-2].values #Extract the frequences from the document\n",
        "  labels = document.iloc[:, -1].values #Extract the classes(labels)\n",
        "  classifier = mainNaiveBayes().fitModel(wordCount, labels) #Fit the model\n",
        "  testSet = countFeatures(sentence) #Create feature set from the test sentence\n",
        "  print(\"\\nThe feature test set is: \", testSet)\n",
        "  predictedSentiment = classifier.predict(testSet)\n",
        "  print(\"Test Sentence: \", sentence)\n",
        "  print(\"Sentiment using Binarized Naïve Bayes - \", getPrediction(predictedSentiment))\n",
        "\n",
        "multinomialNaiveBayes()\n",
        "binarizedNaiveBayes()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset for Multinomial Naive Bayes: \n",
            "    good  poor  great     class  ID\n",
            "0     3     0      3  positive   1\n",
            "1     0     1      2  positive   1\n",
            "2     1     3      0  negative   0\n",
            "3     1     5      2  negative   0\n",
            "4     0     2      0  negative   0\n",
            "\n",
            "The feature test set is:  [[2 1 1]]\n",
            "Test Sentence:  A good, good plot and great characters, but poor acting.\n",
            "Sentiment using Multinomial Naïve Bayes -  Positive\n",
            "\n",
            "Dataset for Binarized Naive Bayes: \n",
            "    good  poor  great     class  ID\n",
            "0     1     0      1  positive   1\n",
            "1     0     1      1  positive   1\n",
            "2     1     1      0  negative   0\n",
            "3     1     1      1  negative   0\n",
            "4     0     1      0  negative   0\n",
            "\n",
            "The feature test set is:  [[2 1 1]]\n",
            "Test Sentence:  A good, good plot and great characters, but poor acting.\n",
            "Sentiment using Binarized Naïve Bayes -  Negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIff7g5_sCJf"
      },
      "source": [
        "**Result:** As demonstrated by the results above, the two models disagree.\n",
        "The Multinomial Naïve Bayes model classifies the test sentence as positive, whereas the Binarized Naïve Bayes model classifies the test sentence as negative."
      ]
    }
  ]
}